{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langevin_sampling.samplers import LangevinDynamics, MetropolisAdjustedLangevin\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "import copy\n",
    "from autoimpute.imputations import MiceImputer, MultipleImputer, SingleImputer\n",
    "import pandas as pd\n",
    "import dill\n",
    "from tqdm import tqdm\n",
    "from mdfeature.KramersRateEvaluator import KramersRateEvaluator\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "def double_well_negative_log(x):\n",
    "    h = 1.75\n",
    "    c = 2\n",
    "    return -(1/4)*(x**2)*(h**4) + (1/2)*(c**2)*(x**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb43e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.dump(est_samples, file = open(\"double_well_samples.pickle\", \"wb\"))\n",
    "est_samples = dill.load(open(\"double_well_samples.pickle\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([1], requires_grad=True, device=device)\n",
    "max_itr = int(3e6)\n",
    "burn_in_samples = 50\n",
    "\n",
    "MALA = True\n",
    "\n",
    "if MALA is True:\n",
    "    sampler = MetropolisAdjustedLangevin(\n",
    "        x,\n",
    "        double_well_negative_log,\n",
    "        lr=1e-1,\n",
    "        lr_final=4e-2,\n",
    "        max_itr=max_itr,\n",
    "        device=device\n",
    "    )\n",
    "else:\n",
    "    sampler = LangevinDynamics(\n",
    "        x,\n",
    "        double_well_negative_log,\n",
    "        lr=0.5,\n",
    "        lr_final=1e-2,\n",
    "        max_itr=max_itr,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "hist_samples = []\n",
    "loss_log = []\n",
    "for j in tqdm(range(max_itr)):\n",
    "    est, loss = sampler.sample()\n",
    "    loss_log.append(loss)\n",
    "    hist_samples.append(est.cpu().numpy())\n",
    "        \n",
    "est_samples = np.array(hist_samples).flatten()[burn_in_samples:]\n",
    "\n",
    "fig = plt.figure(dpi=150, figsize=(9, 4))\n",
    "plt.hist(est_samples, bins=200, density=True)\n",
    "plt.xlabel('x coordinate')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate as interpolate\n",
    "\n",
    "def free_energy_estimate(samples):\n",
    "    \n",
    "    # histogram\n",
    "    counts, coordinate = np.histogram(samples, bins=200)\n",
    "    robust_counts = counts[np.where(counts>50)]\n",
    "    robust_coordinates = coordinate[np.where(counts>50)]\n",
    "    \n",
    "    # log noraml\n",
    "    normalised_counts = robust_counts / np.sum(counts)\n",
    "    with np.errstate(divide='ignore'):\n",
    "        free_energy = - np.log(normalised_counts)\n",
    "    \n",
    "    # nan imputation\n",
    "    for index, energy in enumerate(free_energy):\n",
    "        if energy == np.inf or energy == -np.inf:\n",
    "            free_energy[index] = np.nan\n",
    "            \n",
    "    df = pd.DataFrame({'CV':robust_coordinates, 'F':free_energy})\n",
    "    si = MiceImputer(return_list=True, strategy={\"F\": \"interpolate\"},n=1)\n",
    "    output = si.fit_transform(df)[0][1]\n",
    "    \n",
    "    # smoothing\n",
    "    \n",
    "    dx = 0.001\n",
    "    sigma = 0.03\n",
    "    interpolated_F = interpolate.interp1d(output.CV, output.F, fill_value='extrapolate')\n",
    "    smoothed_range = np.arange(min(output.CV), max(output.CV), dx)\n",
    "    sampled_F = interpolated_F(smoothed_range)\n",
    "\n",
    "    gx = np.arange(-3 * sigma, 3 * sigma, dx)\n",
    "    gaussian = (1/(np.sqrt(2*np.pi *sigma**2))) * np.exp(-(gx / sigma) ** 2 / 2)\n",
    "    smoothed_F = np.convolve(sampled_F, gaussian, mode=\"same\") * dx\n",
    "    \n",
    "    smoothed_range2 = smoothed_range[np.where((np.abs(smoothed_range-max(smoothed_range))>3*sigma) & (np.abs(smoothed_range-min(smoothed_range))>3*sigma))]\n",
    "    smoothed_F = smoothed_F[np.where((np.abs(smoothed_range-max(smoothed_range))>3*sigma) & (np.abs(smoothed_range-min(smoothed_range))>3*sigma))]\n",
    "\n",
    "    return smoothed_F, smoothed_range2\n",
    "\n",
    "free_energy, coordinates = free_energy_estimate(samples=est_samples)\n",
    "\n",
    "linear_shift = free_energy[floor(len(free_energy)/2)] - double_well_negative_log(0)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.plot(coordinates, free_energy - linear_shift, 'k')\n",
    "plt.xlabel('x', fontsize=16)\n",
    "plt.ylabel('Estimated Free Energy', fontsize=16)\n",
    "\n",
    "x_range = np.arange(min(coordinates), max(coordinates), (max(coordinates)-min(coordinates))/1000)\n",
    "plt.plot(x_range, double_well_negative_log(x_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a616f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kre = KramersRateEvaluator(verbose=True)\n",
    "\n",
    "kre.fit(est_samples, \n",
    "        beta=1, \n",
    "        sigmaD=0.075,\n",
    "        sigmaF=0.01,\n",
    "        step_size=4e-2,\n",
    "        lag=1,\n",
    "        bins=300, \n",
    "        impute_free_energy_nans = False,\n",
    "        minima_prominance=1.1, \n",
    "        include_endpoint_minima=False,\n",
    "        cluster_type='kmeans',\n",
    "        options={'k': 200, 'stride': 5, 'max_iter': 150,\n",
    "         'max_centers': 20, 'metric': 'euclidean', 'n_jobs': None, 'dmin': 0.002})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1608571",
   "metadata": {},
   "source": [
    "MFPT \n",
    "\n",
    "$$\n",
    "\\tau = \\int_{x_{min}=-\\frac{h^2}{2c}}^{x_{max}=0} \\frac{dy}{D(y)} \\exp{\\left(\\beta F(y)\\right)} \\int_{\\infty}^{y} dz \\exp{\\left(-\\beta F(z)\\right)}\n",
    "$$\n",
    "\n",
    "Kramer's Rate\n",
    "\n",
    "$$\n",
    "\\nu = \\frac{1}{2\\tau} \n",
    "$$\n",
    "\n",
    "(Note how rate of crossing is $1/2$ the rate of arrival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b1dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "gamma = 1\n",
    "temperature = 300 \n",
    "R = 0.0083144621 # Universal Gas Constant kJ/K/mol\n",
    "beta = 1.0/(temperature*R) # units (kJ/mol)**(-1)\n",
    "x_max = 0\n",
    "x_left_min = - 0.765625 # - h^2 / (2*c)\n",
    "free_energy_interpolate = interp1d(coordinates, free_energy)\n",
    "\n",
    "def diffusion_coefficient(y, beta, gamma):\n",
    "    return 1/(beta*gamma)\n",
    "\n",
    "def kramers_integrand(z, y, beta):\n",
    "    integrand = np.exp(beta*free_energy_interpolate(y))*np.exp(-beta*free_energy_interpolate(z))/(diffusion_coefficient(y, beta, gamma))\n",
    "    \n",
    "    return integrand\n",
    "\n",
    "def lim0(y, beta):\n",
    "    # technically -inf to y\n",
    "    \n",
    "    return [-1.22, y]\n",
    "            \n",
    "lim1 = [x_left_min, x_max]\n",
    "\n",
    "print(f'With a uniform diffusion coefficient of {diffusion_coefficient(0, beta, gamma)}, we obtain a Kramers rate of:')\n",
    "tau, _ = integrate.nquad(kramers_integrand, [lim0, lim1], args=(beta,))\n",
    "\n",
    "rate = 1/(2*tau)\n",
    "\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyemma\n",
    "\n",
    "def relabel_trajectory_by_state_chronology(traj, state_centers):\n",
    "    sorted_indices = np.argsort(np.argsort(state_centers))\n",
    "\n",
    "    # relabel states in trajectory\n",
    "    for idx, state in enumerate(traj):\n",
    "        traj[idx] = sorted_indices[traj[idx]]\n",
    "\n",
    "    return traj\n",
    "\n",
    "print(est_samples)\n",
    "\n",
    "cluster = pyemma.coordinates.cluster_kmeans(est_samples, k=150, max_iter=100)\n",
    "discrete_traj = cluster.dtrajs[0]\n",
    "cluster_centers = cluster.clustercenters.flatten()\n",
    "discrete_traj = relabel_trajectory_by_state_chronology(discrete_traj, cluster_centers)\n",
    "sorted_state_centers = np.sort(cluster_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "its = pyemma.msm.its(discrete_traj)\n",
    "#pyemma.plots.plot_implied_timescales(its)\n",
    "plt.plot(discrete_traj[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18441eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_range = (-0.80, -0.72)   # located in left well\n",
    "final_range = (0.72, 0.80)       # located in right well\n",
    "\n",
    "def compute_states_for_range(given_range, sorted_state_centers):\n",
    "    nstates = len(sorted_state_centers)\n",
    "    voronoi_cell_boundaries = [(sorted_state_centers[i+1]+sorted_state_centers[i])/2\n",
    "                           for i in range(len(sorted_state_centers)-1)]\n",
    "    lower_value = given_range[0]\n",
    "    higher_value = given_range[1]\n",
    "    number_of_lower_states = len([boundary for boundary in voronoi_cell_boundaries if boundary < lower_value])\n",
    "    number_of_upper_states = len([boundary for boundary in voronoi_cell_boundaries if boundary > higher_value])\n",
    "    \n",
    "    lower_state_index = number_of_lower_states\n",
    "    upper_state_index = nstates - number_of_upper_states\n",
    "    \n",
    "    states_in_range = np.arange(lower_state_index, upper_state_index, 1)\n",
    "    \n",
    "    return states_in_range\n",
    "\n",
    "initial_states = compute_states_for_range(initial_range, sorted_state_centers)\n",
    "final_states = compute_states_for_range(final_range, sorted_state_centers)\n",
    "\n",
    "\n",
    "\n",
    "msm = pyemma.msm.estimate_markov_model(discrete_traj, lag=1)\n",
    "mfpt = msm.mfpt(A=initial_states, B=final_states)\n",
    "print(mfpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90332e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 4e-2\n",
    "real_mfpt = mfpt * learning_rate\n",
    "kramers_rate = 1/(2*real_mfpt)\n",
    "print(f\"The estimated Kramers rate for this system is {round(kramers_rate, 3)}/s\")\n",
    "gamma = 1.933805/kramers_rate\n",
    "print(f\"This implies that the gamma value is {round(gamma, 2)}\")\n",
    "print(f\"And that the diffusion coefficient is {round(1/(beta*gamma), 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5d839",
   "metadata": {},
   "source": [
    "## Computing Diffusion Coefficients Through Kramers-Moyal Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441791de",
   "metadata": {},
   "source": [
    "$$\n",
    "c^{(n)}(x, \\tau) = \\int dx' \\left(x' - x\\right)^n p\\left(x', \\tau \\vert x \\right) = \\left< \\left(x(t+\\tau)-x(t)\\right)^n\\right>_{x(t)=x}\n",
    "$$\n",
    "\n",
    "$$\n",
    "c^{(n)}(x_i, \\tau) = \\sum_{j=1}^{N_{bin}} \\left(x_j - x_i\\right)^n p_{ij}^{(\\tau)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "c^{(1)} \\approx D^{(1)}(X) \\tau\n",
    "$$\n",
    "\n",
    "$$\n",
    "c^{(2)}(X, \\tau) \\approx 2 D^{(2)}(X) \\tau + \\left(D^{(1)}(X) \\tau \\right)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "D^{(2)}(x_i) \\approx \\frac{c^{(2)}(x_i, \\tau) - c^{(1)}(x_i, \\tau)^2}{2 \\tau}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8113f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_c(X, n, P):\n",
    "    return np.sum([(X[j]-X)**n * P[:,j] for j in range(len(X))], axis=0)\n",
    "\n",
    "\n",
    "def compute_drift_and_diffusion(traj, lag, step, k):\n",
    "    cluster = pyemma.coordinates.cluster_kmeans(traj, k=k, max_iter=100)\n",
    "    discrete_traj = cluster.dtrajs[0]\n",
    "    cluster_centers = cluster.clustercenters.flatten()\n",
    "    discrete_traj = relabel_trajectory_by_state_chronology(discrete_traj, cluster_centers)\n",
    "    X = np.sort(cluster_centers)\n",
    "\n",
    "    msm = pyemma.msm.estimate_markov_model(discrete_traj, lag=lag)\n",
    "\n",
    "    c1 = calculate_c(X, 1, msm.transition_matrix)\n",
    "    c2 = calculate_c(X, 2, msm.transition_matrix)\n",
    "    c4 = calculate_c(X, 4, msm.transition_matrix)\n",
    "    \n",
    "    tau = lag * step\n",
    "    \n",
    "    D2 = (c2 - c1 **2)/(2*tau)\n",
    "    D4 = (1/(4*3*2*tau))*c4\n",
    "\n",
    "    plt.plot(X, D4/(D2**2))\n",
    "\n",
    "compute_drift_and_diffusion(est_samples, lag=1, step=4e-2, k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_drift_and_diffusion_2(traj, lag, step, k, ax):\n",
    "    cluster = pyemma.coordinates.cluster_kmeans(traj, k=k, max_iter=100)\n",
    "    discrete_traj = cluster.dtrajs[0]\n",
    "    cluster_centers = cluster.clustercenters.flatten()\n",
    "    discrete_traj = relabel_trajectory_by_state_chronology(discrete_traj, cluster_centers)\n",
    "    X = np.sort(cluster_centers)\n",
    "\n",
    "    msm = pyemma.msm.estimate_markov_model(discrete_traj, lag=lag)\n",
    "\n",
    "    c1 = calculate_c(X, 1, msm.transition_matrix)\n",
    "    c2 = calculate_c(X, 2, msm.transition_matrix)\n",
    "    \n",
    "    tau = lag * step\n",
    "    \n",
    "    D2 = (c2 - c1 **2)/(2*tau)\n",
    "    ax.plot(X, D2, label=f\"k={k}\")\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6827d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lags = [1,2,3,4,5,7,9,13,17]\n",
    "cm = plt.cm.PuBuGn(np.linspace(0.25, 0.75, len(lags)))\n",
    "ax = plt.subplot(111)\n",
    "ax.set_prop_cycle('color', list(cm))\n",
    "for idx, lag in enumerate(lags):\n",
    "    compute_drift_and_diffusion_2(est_samples, lag=lag, step=4e-2, k=50, ax=ax)\n",
    "plt.legend(fontsize=18)\n",
    "plt.xlabel(\"x\", fontsize=25)\n",
    "plt.ylabel(r\"$D^{(2)}(x)$\", fontsize=25)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [10,15,20,30,50,70,90,120,150]\n",
    "cm = plt.cm.PuBuGn(np.linspace(0.25, 0.75, len(lags)))\n",
    "ax = plt.subplot(111)\n",
    "ax.set_prop_cycle('color', list(cm))\n",
    "for idx, lag in enumerate(lags):\n",
    "    compute_drift_and_diffusion_2(est_samples, lag=5, step=4e-2, k=k[idx], ax=ax)\n",
    "plt.legend(fontsize=18)\n",
    "plt.xlabel(\"x\", fontsize=25)\n",
    "plt.ylabel(r\"$D^{(2)}(x)$\", fontsize=25)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c550aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(peak_Ds)\n",
    "plt.plot(std_Ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304fdd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_drift_and_diffusion(est_samples, lag=1, step=4e-2, k=10, axs=axs, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcaef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1 * 4e-2\n",
    "cluster = pyemma.coordinates.cluster_kmeans(est_samples, k=4, max_iter=100)\n",
    "discrete_traj = cluster.dtrajs[0]\n",
    "cluster_centers = cluster.clustercenters.flatten()\n",
    "discrete_traj = relabel_trajectory_by_state_chronology(discrete_traj, cluster_centers)\n",
    "X = np.sort(cluster_centers)\n",
    "msm = pyemma.msm.estimate_markov_model(discrete_traj, lag=1)\n",
    "c1 = calculate_c(X, 1, msm.transition_matrix)\n",
    "c2 = calculate_c(X, 2, msm.transition_matrix)\n",
    "D2 = (c2 - c1 **2)/(2*tau)\n",
    "\n",
    "print(\"sorted centers\", X)\n",
    "print(\"transition matrix\", msm.transition_matrix)\n",
    "print(\"c1\", c1)\n",
    "print(\"c2\", c2)\n",
    "print(\"D2\", D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted centers [-0.8242084  -0.31454545  0.3092177   0.8194292 ]\n",
    "transition matrix [[0.74613474 0.23868719 0.0143054  0.00087267]\n",
    " [0.31079655 0.49564999 0.17528846 0.01826499]\n",
    " [0.01844829 0.17360506 0.49550507 0.31244158]\n",
    " [0.00085115 0.01368135 0.23630303 0.74916447]]\n",
    "c1 [ 0.13929848 -0.02835096  0.03021309 -0.13747782]\n",
    "c2 [0.08273556 0.1724196  0.1725795  0.08140567]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78dcdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdfeature.KramersRateEvaluator import KramersRateEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b509b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "kre = KramersRateEvaluator(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc992a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kre.fit(est_samples, \n",
    "        beta, \n",
    "        sigmaD=0.002,\n",
    "        sigmaF=0.00025,\n",
    "        lags= [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
    "        bins=200, \n",
    "        step_size=4e-2,\n",
    "        minima_prominance=0.5,\n",
    "        cluster_type='kmeans',\n",
    "        options={'k': 50, 'stride': 5, 'max_iter': 150,\n",
    "         'max_centers': 1000, 'metric': 'euclidean', 'n_jobs': None, 'dmin': 0.002})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318a80c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
